{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QlearningAgent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBvPsbJfuMD2"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "from collections import defaultdict "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnHhI5uRukcY"
      },
      "source": [
        "class QLearningAgent:\n",
        "     def __init__(self, env):\n",
        "         self.env = env\n",
        "         self.Qs = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    \n",
        "     def train(self, max_episodes = 15000, max_steps = 100, discount_rate = 0.98, learning_rate = 0.1, \n",
        "              exploration_rate_max = 1., exploration_rate_min = 0.01, exploration_decay_rate = 0.001):\n",
        "      \n",
        "          exploration_rate = 1\n",
        "\n",
        "          for e in range(max_episodes):\n",
        "             state = env.reset()\n",
        "             done = False\n",
        "             rewards = 0\n",
        "             for step in range(max_steps):\n",
        "                exploration_rate_threshold = random.uniform(0,1)\n",
        "                if exploration_rate_threshold > exploration_rate:\n",
        "                   action = np.argmax(self.Qs[state,:])\n",
        "                else:\n",
        "                   action = env.action_space.sample()\n",
        "\n",
        "                new_state, reward, done, info = env.step(action)   \n",
        "\n",
        "                self.Qs[state,action] =  (1-learning_rate) * self.Qs[state,action] + \\\n",
        "                     learning_rate *(reward + discount_rate * np.max(self.Qs[new_state,:]))\n",
        "\n",
        "                state = new_state\n",
        "                rewards += reward\n",
        "\n",
        "                if done == True:\n",
        "                   break\n",
        "  \n",
        "                exploration_rate = exploration_rate_min + (exploration_rate_max - exploration_rate_min) * np.exp(-exploration_decay_rate * e)    \n",
        "     \n",
        "          print(self.Qs)\n",
        "\n",
        "     def act(self, state):\n",
        "        return np.argmax(self.Qs[state,:]) "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvVJCMlYxAqM",
        "outputId": "2aab4168-a4a4-48e2-c775-a1179f65aa02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "env = gym.make(\"FrozenLake-v0\")\n",
        "\n",
        "agent = QLearningAgent(env)\n",
        "agent.train()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.36295411 0.34458475 0.3500776  0.3439362 ]\n",
            " [0.21796158 0.27430186 0.17905013 0.31378263]\n",
            " [0.27688725 0.27124336 0.26707536 0.28537232]\n",
            " [0.09237218 0.14103638 0.16952111 0.27245003]\n",
            " [0.38880395 0.32143342 0.349775   0.19199071]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.25545054 0.10125162 0.10355923 0.0651357 ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.31486883 0.32164147 0.3191476  0.45115963]\n",
            " [0.45537542 0.5510316  0.30487133 0.26751389]\n",
            " [0.54708018 0.27617351 0.25197851 0.21362441]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.50528904 0.59160208 0.67554321 0.32814465]\n",
            " [0.67944947 0.85210525 0.69588817 0.69378006]\n",
            " [0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm1bRkFyxvwp",
        "outputId": "08e7f1d1-e4f9-41db-b2c0-ade8fa9ac4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "wins = 0\n",
        "done = False\n",
        "test_env = gym.make(\"FrozenLake-v0\")\n",
        "\n",
        "for episode in range(1000):\n",
        "  state = test_env.reset()\n",
        "  done = False\n",
        "\n",
        "  for step in range(100):\n",
        "     action = agent.act(state)\n",
        "     new_state, reward, done, info = test_env.step(action) \n",
        "\n",
        "     if done == True:\n",
        "        if reward == 1:\n",
        "           wins +=1\n",
        "        break\n",
        "     state = new_state\n",
        "        \n",
        "print(\"wins ratio \", wins/1000) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wins ratio  0.732\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}